boston_scaled <- as.data.frame(boston_scaled)
# First we create the quantile vector of crim:
bins <- quantile(boston_scaled$crim)
bins
# Then we create the categorical variable "crime":
crime <- cut(boston_scaled$crim, breaks = bins, inlcude.lowest = TRUE, label = c("low", "med_low", "med_high", "high"))
table(crime)
boston_scaled <- dplyr::select(boston_scaled, -crim)
boston_scaled <- data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
# Choose randomly 80% of the rows:
ind <- sample(n, size = n*0.8)
# create the train set;
train <- boston_scaled[ind,]
# create the test set:
test <- boston_scaled[-ind,]
lda.fit <- lda(crime ~., data = train)
lda.fit
# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(train$crime)
# plot the lda results
plot(lda.fit, dimen = 2, col=classes, pch= classes)
lda.arrows(lda.fit, myscale = 1)
# we save the correct classes from test data:
correct_classes <- test$crime
# remove the crime variable from the test data:
test <- dplyr::select(test, -crime)
lda.pred <- predict(lda.fit, newdata = test)
table(correct = correct_classes, predicted = lda.pred$class)
table(correct = correct_classes, predicted = lda.pred$class) %>% prop.table() %>% addmargins()
boston_scaled2 <- scale(Boston)
summary(boston_scaled2)
dist_eu <- dist(boston_scaled2)
km <- kmeans(boston_scaled2, centers = 3)
# avoid the kmeans to give us every time different results
set.seed(123)
# set the maximum number of clusters to 10
k_max <- 10
# calculate the total sum of squares:
twcss <- sapply(1:k_max, function(k){kmeans (boston_scaled2, k)$tot.wthinss})
# see graphically the optimal number of clusters:
qplot(x = 1:k_max, y= twcss, geom = 'line')
# change the object to data frame
boston_scaled2 <- as.data.frame(boston_scaled)
dist_eu <- dist(boston_scaled2)
dist_eu <- dist(boston_scaled2)
summary(dist_eu)
km <- kmeans(boston_scaled2, centers = 3)
# change the object to data frame
boston_scaled2 <- as.data.frame(boston_scaled)
dist_eu <- dist(boston_scaled2)
summary(dist_eu)
km <- kmeans(boston_scaled2, centers = 3)
km <- kmeans(boston_scaled2, centers = 3)
str(Boston)
library(MASS)
str(Boston)
install.packages("installr")
library("MASS", lib.loc="~/R/win-library/3.4")
str(Boston)
dim(Boston)
library(corrplot)
library(tidyverse)
cor_matrix <- cor(Boston) %>% round(digits=2)
corrplot.mixed(cor_matrix, lower.col = "black", number.cex = .6)
summary(Boston)
gather(Boston) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()
boston_scaled <- scale(Boston)
summary(boston_scaled)
boston_scaled <- as.data.frame(boston_scaled)
# First we create the quantile vector of crim:
bins <- quantile(boston_scaled$crim)
bins
# Then we create the categorical variable "crime":
crime <- cut(boston_scaled$crim, breaks = bins, inlcude.lowest = TRUE, label = c("low", "med_low", "med_high", "high"))
table(crime)
boston_scaled <- dplyr::select(boston_scaled, -crim)
boston_scaled <- data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
# Choose randomly 80% of the rows:
ind <- sample(n, size = n*0.8)
# create the train set;
train <- boston_scaled[ind,]
# create the test set:
test <- boston_scaled[-ind,]
lda.fit <- lda(crime ~., data = train)
lda.fit
# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(train$crime)
# plot the lda results
plot(lda.fit, dimen = 2, col=classes, pch= classes)
lda.arrows(lda.fit, myscale = 1)
# we save the correct classes from test data:
correct_classes <- test$crime
# remove the crime variable from the test data:
test <- dplyr::select(test, -crime)
lda.pred <- predict(lda.fit, newdata = test)
table(correct = correct_classes, predicted = lda.pred$class)
table(correct = correct_classes, predicted = lda.pred$class) %>% prop.table() %>% addmargins()
boston_scaled2 <- scale(Boston)
summary(boston_scaled2)
# change the object to data frame
boston_scaled2 <- as.data.frame(boston_scaled2)
dist_eu <- dist(boston_scaled2)
summary(dist_eu)
row.has.na <- apply(boston_scaled2, 1, function(x){any(is.na(x))})
sum(row.has.na)
boston_scaled2 <- boston_scaled2[!row.has.na,]
row.has.nan <- apply(boston_scaled2, 1, function(x){any(is.nan(x))})
sum(row.has.nan)
boston_scaled2 <- boston_scaled2[!row.has.nan,]
row.has.inf <- apply(boston_scaled2, 1, function(x){any(is.infinite(x))})
sum(row.has.inf)
boston_scaled2 <- boston_scaled2[!row.has.inf,]
km <- kmeans(boston_scaled2, centers = 3)
# avoid the kmeans to give us every time different results
set.seed(123)
# set the maximum number of clusters to 10
k_max <- 10
# calculate the total sum of squares:
twcss <- sapply(1:k_max, function(k){kmeans (boston_scaled2, k)$tot.wthinss})
# see graphically the optimal number of clusters:
qplot(x = 1:k_max, y= twcss, geom = 'line')
# avoid the kmeans to give us every time different results
set.seed(123)
# set the maximum number of clusters to 10
k_max <- 10
# calculate the total sum of squares:
twcss <- sapply(1:k_max, function(k){kmeans (boston_scaled2, k)$tot.withinss})
# see graphically the optimal number of clusters:
qplot(x = 1:k_max, y = twcss, geom = 'line')
km <- kmeans(boston_scaled2, centers = 2)
pairs(boston_scaled2, col=km$cluster)
km <- kmeans(boston_scaled2, centers = 2)
pairs(boston_scaled2, col=km$cluster)
pairs(boston_scaled2[1:5], col=km$cluster)
pairs(boston_scaled2[6:10], col=km$cluster)
summary(Boston)
boston_scaled3 <- scale(Boston)
summary(boston_scaled3)
km2 <- kmeans(boston_scaled3, center = 3)
boston_scaled3 <- as.data.frame(boston_scaled3)
lda.fit2 <- lda(km2$cluster ~., data=boston_scaled3)
lda.fit2 <- lda(km2$cluster ~., data=boston_scaled3)
# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(km2$cluster)
# plot the lda results
plot(lda.fit2, dimen = 2, col=classes, pch= classes)
lda.arrows(lda.fit, myscale = 1)
model_predictors <- dplyr::select(train, -crime)
# check the dimensions
dim(model_predictors)
dim(lda.fit$scaling)
# matrix multiplication
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling
matrix_product <- as.data.frame(matrix_product)
library("plotly", lib.loc="~/R/win-library/3.4")
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers')
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = train$crime)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = km$cluster)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = km$cluster)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = km$cluster)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = km$cluster)
library("MASS", lib.loc="~/R/win-library/3.4")
str(Boston)
dim(Boston)
library("tidyverse", lib.loc="~/R/win-library/3.4")
library("corrplot", lib.loc="~/R/win-library/3.4")
library(corrplot)
library(tidyverse)
cor_matrix <- cor(Boston) %>% round(digits=2)
corrplot.mixed(cor_matrix, lower.col = "black", number.cex = .6)
summary(Boston)
gather(Boston) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()
boston_scaled <- scale(Boston)
summary(boston_scaled)
boston_scaled <- as.data.frame(boston_scaled)
boston_scaled <- scale(Boston)
summary(boston_scaled)
boston_scaled <- as.data.frame(boston_scaled)
# First we create the quantile vector of crim:
bins <- quantile(boston_scaled$crim)
bins
# Then we create the categorical variable "crime":
crime <- cut(boston_scaled$crim, breaks = bins, inlcude.lowest = TRUE, label = c("low", "med_low", "med_high", "high"))
table(crime)
boston_scaled <- dplyr::select(boston_scaled, -crim)
boston_scaled <- data.frame(boston_scaled, crime)
n <- nrow(boston_scaled)
# Choose randomly 80% of the rows:
ind <- sample(n, size = n*0.8)
# create the train set;
train <- boston_scaled[ind,]
# create the test set:
test <- boston_scaled[-ind,]
lda.fit <- lda(crime ~., data = train)
lda.fit
# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(train$crime)
# plot the lda results
plot(lda.fit, dimen = 2, col=classes, pch= classes)
lda.arrows(lda.fit, myscale = 1)
# we save the correct classes from test data:
correct_classes <- test$crime
# remove the crime variable from the test data:
test <- dplyr::select(test, -crime)
lda.pred <- predict(lda.fit, newdata = test)
table(correct = correct_classes, predicted = lda.pred$class)
table(correct = correct_classes, predicted = lda.pred$class) %>% prop.table() %>% addmargins()
boston_scaled2 <- scale(Boston)
summary(boston_scaled2)
# change the object to data frame
boston_scaled2 <- as.data.frame(boston_scaled2)
dist_eu <- dist(boston_scaled2)
summary(dist_eu)
km <- kmeans(boston_scaled2, centers = 3)
# avoid the kmeans to give us every time different results
set.seed(123)
# set the maximum number of clusters to 10
k_max <- 10
# calculate the total sum of squares:
twcss <- sapply(1:k_max, function(k){kmeans (boston_scaled2, k)$tot.withinss})
# see graphically the optimal number of clusters:
qplot(x = 1:k_max, y = twcss, geom = 'line')
km <- kmeans(boston_scaled2, centers = 2)
pairs(boston_scaled2, col=km$cluster)
pairs(boston_scaled2[1:5], col=km$cluster)
pairs(boston_scaled2[6:10], col=km$cluster)
summary(Boston)
boston_scaled3 <- scale(Boston)
summary(boston_scaled3)
km2 <- kmeans(boston_scaled3, center = 3)
boston_scaled3 <- as.data.frame(boston_scaled3)
lda.fit2 <- lda(km2$cluster ~., data=boston_scaled3)
# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
# target classes as numeric
classes <- as.numeric(km2$cluster)
# plot the lda results
plot(lda.fit2, dimen = 2, col=classes, pch= classes)
lda.arrows(lda.fit, myscale = 1)
model_predictors <- dplyr::select(train, -crime)
# check the dimensions
dim(model_predictors)
dim(lda.fit$scaling)
# matrix multiplication
matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling
matrix_product <- as.data.frame(matrix_product)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers')
library("plotly", lib.loc="~/R/win-library/3.4")
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers')
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = train$crime)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = km$cluster)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = km2$cluster)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = km$cluster)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', col = km$cluster)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = km$cluster)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = train$crime)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = km$cluster)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = km$cluster)
plot_ly(x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers', color = km$cluster)
human <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human2.txt", sep = ",", col.names = TRUE, row.names = TRUE)
install.packages("installr")
human <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human2.txt", sep = ",", col.names = TRUE, row.names = TRUE)
setwd("C:/Users/Elisabet/Desktop/ELI/MASTER'S DEGREE/Open Data Science/GitHub/IODS-project/IODS-project/Data")
human <- read.table("human.csv", header = TRUE, sep = ",")
colnames(human)[7] <- "GNI"
colnames(human)[7]
str(human$GNI)
library(stringr)
str_replace(human$GNI, pattern = ",", replace = "") %>% as.numeric()
human$GNI
human <- str_replace(human$GNI, pattern = ",", replace = "") %>% as.numeric()
human$GNI
human <- mutate(human, GNI = str_replace(human$GNI, pattern = ",", replace = "") %>% as.numeric())
library(dplyr)
human <- mutate(human, GNI = str_replace(human$GNI, pattern = ",", replace = "") %>% as.numeric())
human <- mutate(human, GNI = str_replace(human$GNI, pattern = ",", replace = "") %>% as.numeric())
human <- read.table("human.csv", header = TRUE, sep = ",")
summary(human)
colnames(human)[7] <- "GNI"
str(human$GNI)
human <- mutate(human, GNI = str_replace(human$GNI, pattern = ",", replace = "") %>% as.numeric())
human <- read.table("human.csv", header = TRUE, sep = ",")
str(human)
library(stringr)
library(dplyr)
human <- mutate(human, GNI = str_replace(human$GNI, pattern = ",", replace = "") %>% as.numeric())
human$GNI
keep <- c("country", "ratio.edu2", "ratio.labforce", "yr.eduexp", "lifexp", "GNI", "matermor", "adobirth", "repreparl")
human <- select(human, one_of(keep))
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
str(hd)
dim(hd)
summary(hd)
str(gii)
dim(gii)
summary(gii)
colnames(hd)[1] <- "HDI.rank"
colnames(hd)[2] <- "country"
colnames(hd)[3] <- "HDI"
colnames(hd)[4] <- "lifexp"
colnames(hd)[5] <- "yr.eduexp"
colnames(hd)[6] <- "meanyr.edu"
colnames(hd)[7] <- "GNI"
colnames(hd)[8] <- "GNIrank-HDIrank"
colnames(gii)[1] <- "GII.rank"
colnames(gii)[2] <- "country"
colnames(gii)[3] <- "GII"
colnames(gii)[4] <- "matermor"
colnames(gii)[5] <- "adobirth"
colnames(gii)[6] <- "repreparl"
colnames(gii)[7] <- "edu2F"
colnames(gii)[8] <- "edu2M"
colnames(gii)[9] <- "labforceF"
colnames(gii)[10] <- "labforceM"
colnames(hd)
colnames(gii)
gii <- mutate(gii, ratio.edu2 = gii$edu2F/gii$edu2M)
gii <- mutate(gii, ratio.labforce = gii$labforceF/gii$labforceM)
colnames(gii)
summary(gii$ratio.edu2)
summary(gii$ratio.labforce)
library(dplyr)
human <- inner_join(hd, gii, by = "country")
glimpse(human)
setwd("C:/Users/Elisabet/Desktop/ELI/MASTER'S DEGREE/Open Data Science/GitHub/IODS-project/IODS-project/Data")
write.table(human, file = "human.csv", sep = ",", col.names = TRUE)
write.table(human, file = "human.csv", sep = ",", col.names = TRUE, row.names = FALSE)
human <- read.table("human.csv", header = TRUE, sep = ",")
str(human)
library(stringr)
library(dplyr)
human <- mutate(human, GNI = str_replace(human$GNI, pattern = ",", replace = "") %>% as.numeric())
human$GNI
keep <- c("country", "ratio.edu2", "ratio.labforce", "yr.eduexp", "lifexp", "GNI", "matermor", "adobirth", "repreparl")
human <- select(human, one_of(keep))
data.frame(human, comp = complete.cases(human))
human_ <- filter(human, complete.cases(human))
str(human_)
tail(human_, n= 10)
last <- nrow(human_) - 7
human_ <- human_[1:last,]
rownames(human_) <- human_$country
human_ <- select(human_, -country)
str(human_)
glimpse(human_)
setwd("C:/Users/Elisabet/Desktop/ELI/MASTER'S DEGREE/Open Data Science/GitHub/IODS-project/IODS-project/Data")
write.table(human_, file = "human.csv", sep = ",", col.names = TRUE, row.names = TRUE)
human <- read.table(file="human.csv", header = TRUE, row.names = 1)
str(human)
write.table(human_, file = "human.csv", sep = " ", col.names = TRUE, row.names = TRUE)
human <- read.table(file="human.csv", header = TRUE, row.names = 1)
str(human)
setwd("C:/Users/Elisabet/Desktop/ELI/MASTER'S DEGREE/Open Data Science/GitHub/IODS-project/IODS-project/Data")
human <- read.table(file="human.csv", header = TRUE, row.names = 1)
human <- read.table(file="C:/Users/Elisabet/Desktop/ELI/MASTER'S DEGREE/Open Data Science/GitHub/IODS-project/IODS-project/Data/human.csv", header = TRUE, row.names = 1)
str(human)
dim(human)
str(human)
dim(human)
human <- read.table(file="C:/Users/Elisabet/Desktop/ELI/MASTER'S DEGREE/Open Data Science/GitHub/IODS-project/IODS-project/Data/human.csv", header = TRUE, row.names = 1)
str(human)
str(human)
dim(human)
summary(human)
label <- c("ratio.edu2", "ratio.labforce", "yr.eduexp", "lifexp", "GNI", "matermor", "adobirth", "repreparl")
variable <- c("Ratio of female vs male population with at least secondary education", " Ratio of female vs male population in the labour force", " Expected years of schooling", "Life expectancy at birth", "Gross National Income per capita", "Maternal mortality ratio", "Adolescent birth rate", "Percetange of female representatives in parliament")
legend <- data.frame((label, variable))
label <- c("ratio.edu2", "ratio.labforce", "yr.eduexp", "lifexp", "GNI", "matermor", "adobirth", "repreparl")
variable <- c("Ratio of female vs male population with at least secondary education", " Ratio of female vs male population in the labour force", " Expected years of schooling", "Life expectancy at birth", "Gross National Income per capita", "Maternal mortality ratio", "Adolescent birth rate", "Percetange of female representatives in parliament")
legend <- data.frame(label, variable)
kable(legend, "html") %>%
kable_styling(bootstrap_options = "striped", full_width = F)
library("xtable", lib.loc="~/R/win-library/3.4")
label <- c("ratio.edu2", "ratio.labforce", "yr.eduexp", "lifexp", "GNI", "matermor", "adobirth", "repreparl")
variable <- c("Ratio of female vs male population with at least secondary education", " Ratio of female vs male population in the labour force", " Expected years of schooling", "Life expectancy at birth", "Gross National Income per capita", "Maternal mortality ratio", "Adolescent birth rate", "Percetange of female representatives in parliament")
legend <- data.frame(label, variable)
kable(legend, "html") %>%
kable_styling(bootstrap_options = "striped", full_width = F)
summary(human)
library(GGally)
ggpairs(human)
library(corrplot)
cor(human) %>% corrplot()
pca_human <- prcomp(human)
summary(pca_human)
s <- summary(pca_human)
pca_pr <- round(100*s$importance[2,], digits=1)
summary(pca_human)
s <- summary(pca_human)
s
pca_pr <- round(100*s$importance[2,], digits=1)
s <- summary(pca_human)
s
pca_pr <- round(100*s$importance[2,], digits=1)
s <- summary(pca_human)
s
pca_pr <- round(100*s$importance[2,], digits=1)
pca_pr
biplot(pca_human, choices = 1:2, cex = c(0.8, 1))
biplot(pca_human, choices = 1:2, cex = c(0.6, 1))
scale(human)
pca_human <- prcomp(human)
s <- summary(pca_human)
pca_pr <- round(100*s$importance[2,], digits=1)
biplot(pca_human, choices = 1:2, cex = c(0.8, 1))
scale(human)
pca_human <- prcomp(human)
pca_human
s <- summary(pca_human)
s
pca_pr <- round(100*s$importance[2,], digits=1)
pca_pr
scale(human)
pca_human <- prcomp(human)
s <- summary(pca_human)
s
pca_pr <- round(100*s$importance[2,], digits=1)
pca_pr
human <- scale(human)
pca_human <- prcomp(human)
s <- summary(pca_human)
s
pca_pr <- round(100*s$importance[2,], digits=1)
pca_pr
biplot(pca_human, choices = 1:2, cex = c(0.8, 1))
biplot(pca_human, choices = 1:2, cex = c(0.6, 1))
biplot(pca_human, choices = 1:2, cex = c(0.6, 0.9))
pca_lab <- paste0(names(pca_pr), "(", pca_pr, "%)")
biplot(pca_human, cex = (0.8, 1), col=c("grey40", "deeppink2"), xlab= pc_lab[1], ylab = pc_lab[2])
pca_lab <- paste0(names(pca_pr), "(", pca_pr, "%)")
biplot(pca_human, cex = (0.8, 1), col=c("grey40", "deeppink2"), xlab= pc_lab[1], ylab = pc_lab[2])
pca_lab <- paste0(names(pca_pr), "(", pca_pr, "%)")
biplot(pca_human, cex = c(0.8, 1), col=c("grey40", "deeppink2"), xlab= pc_lab[1], ylab = pc_lab[2])
pca_lab <- paste0(names(pca_pr), "(", pca_pr, "%)")
biplot(pca_human, cex = c(0.8, 1), col=c("grey40", "deeppink2"), xlab= pca_lab[1], ylab = pca_lab[2])
pca_lab <- paste0(names(pca_pr), "(", pca_pr, "%)")
biplot(pca_human, cex = c(0.6, 1), col=c("grey40", "deeppink2"), xlab= pca_lab[1], ylab = pca_lab[2])
library(FactoMineR)
install.packages("FactoMineR")
library(FactoMineR)
library(FactoMineR)
str(tea)
library(FactoMineR)
str(tea)
library("dplyr", lib.loc="~/R/win-library/3.4")
library("ggplot2", lib.loc="~/R/win-library/3.4")
library("tidyr", lib.loc="~/R/win-library/3.4")
library(FactoMineR)
str(tea)
library(FactoMineR)
str(tea)
library(FactoMineR)
data("tea")
str(tea)
dim(tea)
gather(tea) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
keep_columns <- c("Tea", "How", "how", "sugar", "where", "lunch")
tea_time <- select(tea, one_of(keep_columns))
gather(tea_time) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
mca <- MCA(tea_time, graph = FALSE)
summary(mca)
plot(mca, invisible = "var", habillage = "quali")
plot(mca, invisible = "ind", habillage = "quali")
plot(mca, invisible = "ind", habillage = "quali")
plot(mca, invisible = "var", habillage = "quali")
library("corrplot", lib.loc="~/R/win-library/3.4")
